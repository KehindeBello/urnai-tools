from .abneuralnetwork import ABNeuralNetwork 
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, Activation
from keras.optimizers import Adam
from keras import backend as K

class KerasDeepNeuralNetwork(ABNeuralNetwork):
    """
    Implementation of a Deep Neural Network using Keras

    Arguments:
        action_output_size: 
            Number of output actions
        state_input_shape: 
            Shape of the input
        build_model: 
            A dict representing the NN's layers. Can be generated by the ModelBuilder.get_model_layout() method from an instantiated ModelBuilder object.
        gamma: 
            Gamma parameter in the Deep Q Learning algorithm
        alpha: 
            Learning Rate
        seed: (default = none)
    """

    def __init__(self, action_output_size, state_input_shape, build_model, gamma, alpha, seed = None, batch_size=32):     
        super().__init__(action_output_size, state_input_shape, build_model, gamma, alpha, seed, batch_size)

        self.model.compile(optimizer=Adam(lr=self.alpha), loss='mse', metrics=['accuracy'])


    def add_input_layer(self, idx):
        self.model.add(Dense(self.build_model[idx]['nodes'], input_dim=self.build_model[idx]['shape'][1], activation='relu'))

    def add_output_layer(self, idx):
        self.model.add(Dense(self.build_model[idx]['length'], activation='linear'))

    def add_fully_connected_layer(self, idx):
        self.model.add(Dense(self.build_model[idx]['nodes'], activation='relu'))

    def add_convolutional_layer(self, idx):
        # if idx is zero it means this is an input layer, so we pass input_shape to keras
        if idx == 0:
            self.model.add(     Conv2D(
                                filters=self.build_model[idx]['filters'], 
                                kernel_size=self.build_model[idx]['filter_shape'], 
                                activation = self.build_model[idx]['activation'],
                                padding = self.build_model[idx]['padding'],
                                strides = self.build_model[idx]['strides'],
                                data_format = self.build_model[idx]['data_format'],
                                dilation_rate = self.build_model[idx]['dilation_rate'],
                                groups = self.build_model[idx]['groups'],
                                input_shape = self.build_model[idx]['input_shape']
                                )
                            )
        else:
            self.model.add(     Conv2D(
                                filters=self.build_model[idx]['filters'], 
                                kernel_size=self.build_model[idx]['filter_shape'], 
                                activation=self.build_model[idx]['activation'],
                                padding = self.build_model[idx]['padding'],
                                strides = self.build_model[idx]['strides'],
                                data_format = self.build_model[idx]['data_format'],
                                dilation_rate = self.build_model[idx]['dilation_rate'],
                                groups = self.build_model[idx]['groups']
                                )
                            )

    def add_maxpooling_layer(self, idx):
        self.model.add(     MaxPooling2D(
                            pool_size=self.build_model[idx]['pool_size'],
                            strides=self.build_model[idx]['strides'],
                            padding=self.build_model[idx]['padding'],
                            data_format=self.build_model[idx]['data_format']
                            )
                        )
    
    def add_flatten_layer(self, idx):
        self.model.add(Flatten())

    def update(self, state, target_output):
        loss = self.model.fit(state, target_output, batch_size=self.batch_size, shuffle=False, verbose=0)

    def get_output(self, state):
        return self.model.predict(state)

    def set_seed(self, seed) -> None:  
        if seed != None:
            import tensorflow as tf
            tf.random.set_seed(seed)
        return seed

    def create_base_model(self):
        model = Sequential()
        return model

    def save_extra(self, persist_path):
        self.model.save_weights(self.get_full_persistance_path(persist_path)+".h5")

    def load_extra(self, persist_path):
        import os
        exists = os.path.isfile(self.get_full_persistance_path(persist_path)+".h5")

        if(exists):
            self.__init__(self.action_output_size, self.state_input_shape, self.build_model, self.gamma, self.alpha, self.seed, self.batch_size)
            self.model.load_weights(self.get_full_persistance_path(persist_path)+".h5")

class DNNCustomModelOverrideExample(KerasDeepNeuralNetwork):
    def __init__(self, action_output_size, state_input_shape, build_model, gamma, alpha, seed = None, batch_size=32):        
        super().__init__(action_output_size, state_input_shape, build_model, gamma, alpha, seed, batch_size)
    
    def make_model(self):
        self.model = Sequential()

        self.model.add(Dense(50, activation='relu', input_dim=self.state_input_shape))
        self.model.add(Dense(50, activation='relu'))
        self.model.add(Dense(self.action_output_size, activation='linear'))

        self.model.compile(optimizer=Adam(lr=self.alpha), loss='mse', metrics=['accuracy'])